name: "darkent448"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 544
input_dim: 544
layer {
    bottom: "data"
    top: "layer1-conv"
    name: "layer1-conv"
    type: "Convolution"
    convolution_param {
        num_output: 32
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer1-conv"
    top: "layer1-conv"
    name: "layer1-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer1-conv"
    top: "layer1-conv"
    name: "layer1-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer1-conv"
    top: "layer1-conv"
    name: "layer1-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer1-conv"
    top: "layer2-maxpool"
    name: "layer2-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
    }
}
layer {
    bottom: "layer2-maxpool"
    top: "layer3-conv"
    name: "layer3-conv"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer3-conv"
    top: "layer3-conv"
    name: "layer3-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer3-conv"
    top: "layer3-conv"
    name: "layer3-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer3-conv"
    top: "layer3-conv"
    name: "layer3-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer3-conv"
    top: "layer4-maxpool"
    name: "layer4-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
    }
}
layer {
    bottom: "layer4-maxpool"
    top: "layer5-conv"
    name: "layer5-conv"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer5-conv"
    top: "layer5-conv"
    name: "layer5-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer5-conv"
    top: "layer5-conv"
    name: "layer5-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer5-conv"
    top: "layer5-conv"
    name: "layer5-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer5-conv"
    top: "layer6-conv"
    name: "layer6-conv"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer6-conv"
    top: "layer6-conv"
    name: "layer6-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer6-conv"
    top: "layer6-conv"
    name: "layer6-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer6-conv"
    top: "layer6-conv"
    name: "layer6-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer6-conv"
    top: "layer7-conv"
    name: "layer7-conv"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer7-conv"
    top: "layer7-conv"
    name: "layer7-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer7-conv"
    top: "layer7-conv"
    name: "layer7-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer7-conv"
    top: "layer7-conv"
    name: "layer7-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer7-conv"
    top: "layer8-maxpool"
    name: "layer8-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
    }
}
layer {
    bottom: "layer8-maxpool"
    top: "layer9-conv"
    name: "layer9-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer9-conv"
    top: "layer9-conv"
    name: "layer9-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer9-conv"
    top: "layer9-conv"
    name: "layer9-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer9-conv"
    top: "layer9-conv"
    name: "layer9-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer9-conv"
    top: "layer10-conv"
    name: "layer10-conv"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer10-conv"
    top: "layer10-conv"
    name: "layer10-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer10-conv"
    top: "layer10-conv"
    name: "layer10-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer10-conv"
    top: "layer10-conv"
    name: "layer10-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer10-conv"
    top: "layer11-conv"
    name: "layer11-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer11-conv"
    top: "layer11-conv"
    name: "layer11-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer11-conv"
    top: "layer11-conv"
    name: "layer11-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer11-conv"
    top: "layer11-conv"
    name: "layer11-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer11-conv"
    top: "layer12-maxpool"
    name: "layer12-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
    }
}
layer {
    bottom: "layer12-maxpool"
    top: "layer13-conv"
    name: "layer13-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer13-conv"
    top: "layer13-conv"
    name: "layer13-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer13-conv"
    top: "layer13-conv"
    name: "layer13-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer13-conv"
    top: "layer13-conv"
    name: "layer13-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer13-conv"
    top: "layer14-conv"
    name: "layer14-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer14-conv"
    top: "layer14-conv"
    name: "layer14-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer14-conv"
    top: "layer14-conv"
    name: "layer14-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer14-conv"
    top: "layer14-conv"
    name: "layer14-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer14-conv"
    top: "layer15-conv"
    name: "layer15-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer15-conv"
    top: "layer15-conv"
    name: "layer15-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer15-conv"
    top: "layer15-conv"
    name: "layer15-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer15-conv"
    top: "layer15-conv"
    name: "layer15-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer15-conv"
    top: "layer16-conv"
    name: "layer16-conv"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer16-conv"
    top: "layer16-conv"
    name: "layer16-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer16-conv"
    top: "layer16-conv"
    name: "layer16-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer16-conv"
    top: "layer16-conv"
    name: "layer16-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer16-conv"
    top: "layer17-conv"
    name: "layer17-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer17-conv"
    top: "layer17-conv"
    name: "layer17-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer17-conv"
    top: "layer17-conv"
    name: "layer17-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer17-conv"
    top: "layer17-conv"
    name: "layer17-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer17-conv"
    top: "layer18-maxpool"
    name: "layer18-maxpool"
    type: "Pooling"
    pooling_param {
        kernel_size: 2
        stride: 2
        pool: MAX
    }
}
layer {
    bottom: "layer18-maxpool"
    top: "layer19-conv"
    name: "layer19-conv"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer19-conv"
    top: "layer19-conv"
    name: "layer19-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer19-conv"
    top: "layer19-conv"
    name: "layer19-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer19-conv"
    top: "layer19-conv"
    name: "layer19-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer19-conv"
    top: "layer20-conv"
    name: "layer20-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer20-conv"
    top: "layer20-conv"
    name: "layer20-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer20-conv"
    top: "layer20-conv"
    name: "layer20-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer20-conv"
    top: "layer20-conv"
    name: "layer20-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer20-conv"
    top: "layer21-conv"
    name: "layer21-conv"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer21-conv"
    top: "layer21-conv"
    name: "layer21-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer21-conv"
    top: "layer21-conv"
    name: "layer21-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer21-conv"
    top: "layer21-conv"
    name: "layer21-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer21-conv"
    top: "layer22-conv"
    name: "layer22-conv"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer22-conv"
    top: "layer22-conv"
    name: "layer22-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer22-conv"
    top: "layer22-conv"
    name: "layer22-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer22-conv"
    top: "layer22-conv"
    name: "layer22-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer22-conv"
    top: "layer23-conv"
    name: "layer23-conv"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "layer23-conv"
    top: "layer23-conv"
    name: "layer23-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "layer23-conv"
    top: "layer23-conv"
    name: "layer23-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "layer23-conv"
    top: "layer23-conv"
    name: "layer23-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer23-conv"
    top: "extra_layer24-conv"
    name: "extra_layer24-conv"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "extra_layer24-conv"
    top: "extra_layer24-conv"
    name: "extra_layer24-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "extra_layer24-conv"
    top: "extra_layer24-conv"
    name: "extra_layer24-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "extra_layer24-conv"
    top: "extra_layer24-conv"
    name: "extra_layer24-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "extra_layer24-conv"
    top: "extra_layer25-conv"
    name: "extra_layer25-conv"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "extra_layer25-conv"
    top: "extra_layer25-conv"
    name: "extra_layer25-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "extra_layer25-conv"
    top: "extra_layer25-conv"
    name: "extra_layer25-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "extra_layer25-conv"
    top: "extra_layer25-conv"
    name: "extra_layer25-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "layer17-conv"
    top: "extra_layer26-conv"
    name: "extra_layer26-conv"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "extra_layer26-conv"
    top: "extra_layer26-conv"
    name: "extra_layer26-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "extra_layer26-conv"
    top: "extra_layer26-conv"
    name: "extra_layer26-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "extra_layer26-conv"
    top: "extra_layer26-conv"
    name: "extra_layer26-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "extra_layer26-conv"
    top: "extra_layer26-reorg"
    name: "extra_layer-reorg"
    type: "Reorg"
}
layer {
    bottom: "extra_layer26-reorg"
	bottom: "extra_layer25-conv"
    top: "extra_layer-concat"
    name: "extra_layer-concat"
    type: "Concat"
    concat_param {
     axis: 1
    }
}
layer {
    bottom: "extra_layer-concat"
    top: "extra_layer27-conv"
    name: "extra_layer27-conv"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
}
layer {
    bottom: "extra_layer27-conv"
    top: "extra_layer27-conv"
    name: "extra_layer27-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "extra_layer27-conv"
    top: "extra_layer27-conv"
    name: "extra_layer27-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
    bottom: "extra_layer27-conv"
    top: "extra_layer27-conv"
    name: "extra_layer27-act"
    type: "ReLU"
    relu_param {
        negative_slope: 0.1
    }
}
layer {
    bottom: "extra_layer27-conv"
    top: "deconv1_lane"
    name: "deconv1_lane"
    type: "Deconvolution"
    convolution_param {
        num_output: 64
        kernel_size: 2
        pad: 0
        stride: 2
        bias_term: true
    }
}
layer {
    bottom: "deconv1_lane"
    top: "deconv1_lane"
    name: "deconv1_lane-bn"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    bottom: "deconv1_lane"
    top: "deconv1_lane"
    name: "deconv1_lane-scale"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}
layer {
  name: "deconv1_lane_relu"
  type: "ReLU"
  bottom: "deconv1_lane"
  top: "deconv1_lane"
  relu_param {
        negative_slope: 0.1
    }
}


layer {
  name: "reorg4"
  type: "Convolution"
  bottom: "layer11-conv"
  top: "reorg4"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg4_relu"
  type: "ReLU"
  bottom: "reorg4"
  top: "reorg4"
}
layer {
  name: "concat4"
  type: "Concat"
  bottom: "reorg4"
  bottom: "deconv1_lane"
  top: "concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "reduce2_lane"
  type: "Convolution"
  bottom: "concat4"
  top: "reduce2_lane"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce2_lane_relu"
  type: "ReLU"
  bottom: "reduce2_lane"
  top: "reduce2_lane"
}
layer {
  name: "deconv2_lane"
  type: "Deconvolution"
  bottom: "reduce2_lane"
  top: "deconv2_lane"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv2_lane_relu"
  type: "ReLU"
  bottom: "deconv2_lane"
  top: "deconv2_lane"
}
layer {
  name: "reorg3"
  type: "Convolution"
  bottom: "layer7-conv"
  top: "reorg3"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg3_relu"
  type: "ReLU"
  bottom: "reorg3"
  top: "reorg3"
}
layer {
  name: "concat3"
  type: "Concat"
  bottom: "reorg3"
  bottom: "deconv2_lane"
  top: "concat3"
  concat_param {
    axis: 1
  }
}layer {
  name: "reduce3_lane"
  type: "Convolution"
  bottom: "concat3"
  top: "reduce3_lane"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce3_lane_relu"
  type: "ReLU"
  bottom: "reduce3_lane"
  top: "reduce3_lane"
}
layer {
  name: "deconv3_lane"
  type: "Deconvolution"
  bottom: "reduce3_lane"
  top: "deconv3_lane"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv3_lane_relu"
  type: "ReLU"
  bottom: "deconv3_lane"
  top: "deconv3_lane"
}
layer {
  name: "reorg2"
  type: "Convolution"
  bottom: "layer3-conv"
  top: "reorg2"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg2_relu"
  type: "ReLU"
  bottom: "reorg2"
  top: "reorg2"
}
layer {
  name: "concat2"
  type: "Concat"
  bottom: "reorg2"
  bottom: "deconv3_lane"
  top: "concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "reduce4_lane"
  type: "Convolution"
  bottom: "concat2"
  top: "reduce4_lane"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce4_lane_relu"
  type: "ReLU"
  bottom: "reduce4_lane"
  top: "reduce4_lane"
}
layer {
  name: "deconv4_lane"
  type: "Deconvolution"
  bottom: "reduce4_lane"
  top: "deconv4_lane"
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv4_lane_relu"
  type: "ReLU"
  bottom: "deconv4_lane"
  top: "deconv4_lane"
}
layer {
  name: "reorg1"
  type: "Convolution"
  bottom: "layer1-conv"
  top: "reorg1"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg1_relu"
  type: "ReLU"
  bottom: "reorg1"
  top: "reorg1"
}
layer {
  name: "concat1"
  type: "Concat"
  bottom: "reorg1"
  bottom: "deconv4_lane"
  top: "concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv_out"
  type: "Convolution"
  bottom: "concat1"
  top: "conv_out"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "seg_prob"
  type: "Softmax"
  bottom: "conv_out"
  top: "seg_prob"
  softmax_param {
    axis: 1
  }
}

